{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of the below code is using work by https://github.com/jamesmullenbach/caml-mimic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import RegexpTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIMIC_4_DIR = \"C:/Users/Buse/Desktop/Zurich/Thesis/Codebase/thesis_playground/Data/MIMIC-IV\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat(row, is_diag):\n",
    "    \"\"\"\n",
    "        Put a period in the right place because the MIMIC-3 data files exclude them.\n",
    "        Generally, procedure codes have dots after the first two digits, \n",
    "        while diagnosis codes have dots after the first three digits.\n",
    "    \"\"\"\n",
    "    code = str(row[\"icd_code\"])\n",
    "    try:\n",
    "        version = int(row[\"icd_version\"])\n",
    "    except:\n",
    "        print(row, row[\"icd_version\"])\n",
    "        return code\n",
    "    if version == 9:\n",
    "        code = ''.join(code.split('.'))\n",
    "        if is_diag:\n",
    "            if code.startswith('E'):\n",
    "                if len(code) > 4:\n",
    "                    code = code[:4] + '.' + code[4:]\n",
    "            else:\n",
    "                if len(code) > 3:\n",
    "                    code = code[:3] + '.' + code[3:]\n",
    "        else:\n",
    "            code = code[:2] + '.' + code[2:]\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_discharge_summaries(out_file):\n",
    "    notes_file = '%s/discharge.csv' % (MIMIC_4_DIR)\n",
    "    print(\"processing notes file\")\n",
    "    with open(notes_file, 'r', encoding=\"utf8\") as csvfile:\n",
    "        with open(out_file, 'w', encoding=\"utf-8\") as outfile:\n",
    "            print(\"writing to %s\" % (out_file))\n",
    "            outfile.write(','.join(['SUBJECT_ID', 'HADM_ID', 'CHARTTIME', 'TEXT']) + '\\n')\n",
    "            notereader = csv.reader(csvfile)\n",
    "            #header\n",
    "            next(notereader)\n",
    "            i = 0\n",
    "            for line in tqdm(notereader):\n",
    "                subj = int(line[1])\n",
    "                note = line[7]\n",
    "                #tokenize, lowercase and remove numerics\n",
    "                tokens = [t.lower() for t in tokenizer.tokenize(note) if not t.isnumeric()]\n",
    "                text = '\"' + ' '.join(tokens) + '\"'\n",
    "                outfile.write(','.join([line[1], line[2], line[5], text]) + '\\n')\n",
    "                i += 1\n",
    "    return out_file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = 'full' #use all available labels in the dataset for prediction\n",
    "notes_file = '%s/discharge.csv' % MIMIC_4_DIR # raw note events downloaded from MIMIC-IV\n",
    "vocab_size = 'full' #don't limit the vocab size to a specific number\n",
    "vocab_min = 3 #discard tokens appearing in fewer than this many documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine diagnosis and procedure codes and reformat them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The codes in MIMIC-III are given in separate files for procedures and diagnoses, and the codes are given without periods, which might lead to collisions if we naively combine them. So we have to add the periods back in the right place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfproc = pd.read_csv('%s/procedures_icd.csv' % MIMIC_4_DIR)\n",
    "dfdiag = pd.read_csv('%s/diagnoses_icd.csv' % MIMIC_4_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfdiag['absolute_code'] = dfdiag.apply(lambda row: str(reformat(row, True)), axis=1)\n",
    "dfproc['absolute_code'] = dfproc.apply(lambda row: str(reformat(row, False)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfcodes = pd.concat([dfdiag, dfproc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfcodes.to_csv('%s/all_codes.csv' % MIMIC_4_DIR, index=False,\n",
    "               columns=['subject_id', 'hadm_id', 'seq_num', 'absolute_code', 'icd_version'],\n",
    "               header=['SUBJECT_ID', 'HADM_ID', 'SEQ_NUM', 'ICD_CODE', 'ICD_VERSION'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many codes are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "38399"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "#In the full dataset (not just discharge summaries)\n",
    "df = pd.read_csv('%s/all_codes.csv' % MIMIC_4_DIR, dtype={\"ICD_CODE\": str})\n",
    "len(df['ICD_CODE'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "11616"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "len(df[df.ICD_VERSION == 9].ICD_CODE.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "26788"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "len(df[df.ICD_VERSION == 10].ICD_CODE.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploration suggests there are same labeled codes in 9 and 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'E848', 'E851', 'E882', 'E895', 'E896'}"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "icd9_set_temp  = set(df[df.ICD_VERSION == 9].ICD_CODE.unique())\n",
    "icd10_set_temp = set(df[df.ICD_VERSION == 10].ICD_CODE.unique())\n",
    "icd9_set_temp.intersection(icd10_set_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They mean completely different things in ICD-9 and ICD-10 so we can ignore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and preprocess raw text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing time!\n",
    "\n",
    "This will:\n",
    "- Select only discharge summaries and their addenda\n",
    "- remove punctuation and numeric-only tokens, removing 500 but keeping 250mg\n",
    "- lowercase all tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "processing notes file\nwriting to C:/Users/Buse/Desktop/Zurich/Thesis/Codebase/thesis_playground/Data/MIMIC-IV/disch_full.csv\n331794it [07:37, 724.97it/s]\n"
    }
   ],
   "source": [
    "#This reads all notes, selects only the discharge summaries, and tokenizes them, returning the output filename\n",
    "disch_full_file = write_discharge_summaries(out_file=\"%s/disch_full.csv\" % MIMIC_4_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read this in and see what kind of data we're working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('%s/disch_full.csv' % MIMIC_4_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "331794"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#How many admissions?\n",
    "len(df['HADM_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's sort by SUBJECT_ID and HADM_ID to make a correspondence with the MIMIC-4 label file\n",
    "df = df.sort_values(['SUBJECT_ID', 'HADM_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the label file by the same\n",
    "dfl = pd.read_csv('%s/all_codes.csv' % MIMIC_4_DIR)\n",
    "dfl = dfl.sort_values(['SUBJECT_ID', 'HADM_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(331794, 430876)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "len(df['HADM_ID'].unique()), len(dfl['HADM_ID'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidate labels with set of discharge summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there were some HADM_ID's that didn't have discharge summaries, so they weren't included with our notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Let's filter out these HADM_ID's\n",
    "hadm_ids = set(df['HADM_ID'])\n",
    "with open('%s/all_codes.csv' % MIMIC_4_DIR, 'r') as lf:\n",
    "    with open('%s/all_codes_filtered.csv' % MIMIC_4_DIR, 'w') as of:\n",
    "        w = csv.writer(of)\n",
    "        w.writerow(['SUBJECT_ID', 'HADM_ID', 'ICD_CODE', 'ICD_VERSION', 'ADMITTIME', 'DISCHTIME'])\n",
    "        r = csv.reader(lf)\n",
    "        #header\n",
    "        next(r)\n",
    "        for i,row in enumerate(r):\n",
    "            hadm_id = int(row[1])\n",
    "            #print(hadm_id)\n",
    "            #break\n",
    "            if hadm_id in hadm_ids:\n",
    "                w.writerow(row[0:2] + row[3:5] + ['', ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfl = pd.read_csv('%s/all_codes_filtered.csv' % MIMIC_4_DIR, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "331669"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "len(dfl['HADM_ID'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like there are some discharge summaries that don't have ICD codes, we already filtered them out as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "125"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "len(hadm_ids.difference(dfl['HADM_ID'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we still need to sort it by HADM_ID\n",
    "dfl = dfl.sort_values(['SUBJECT_ID', 'HADM_ID'])\n",
    "dfl.to_csv('%s/all_codes_filtered.csv' % MIMIC_4_DIR, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create two seperate tables for ICD-9 and ICD-10 codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfl[dfl.ICD_VERSION == 9].to_csv('%s/all_codes_filtered_ICD9.csv' % MIMIC_4_DIR, index=False,\n",
    "               columns=['SUBJECT_ID', 'HADM_ID', 'ICD_CODE', 'ADMITTIME', 'DISCHTIME'],\n",
    "               header=['SUBJECT_ID', 'HADM_ID', 'ICD_CODE', 'ADMITTIME', 'DISCHTIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "11331"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "len(dfl[dfl.ICD_VERSION == 9].ICD_CODE.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "209359"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "len(dfl[dfl.ICD_VERSION == 9].HADM_ID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfl[dfl.ICD_VERSION == 10].to_csv('%s/all_codes_filtered_ICD10.csv' % MIMIC_4_DIR, index=False,\n",
    "               columns=['SUBJECT_ID', 'HADM_ID', 'ICD_CODE', 'ADMITTIME', 'DISCHTIME'],\n",
    "               header=['SUBJECT_ID', 'HADM_ID', 'ICD_CODE', 'ADMITTIME', 'DISCHTIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "26098"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "len(dfl[dfl.ICD_VERSION == 10].ICD_CODE.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "122317"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "len(dfl[dfl.ICD_VERSION == 10].HADM_ID.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append labels to notes in a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now let's append each instance with all of its codes\n",
    "#this is pretty non-trivial so let's use this script I wrote, which requires the notes to be written to file\n",
    "sorted_file = '%s/disch_full.csv' % MIMIC_4_DIR\n",
    "df.to_csv(sorted_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CONCATENATING\n0 done\n10000 done\n20000 done\n30000 done\n40000 done\n50000 done\n60000 done\n70000 done\n80000 done\n90000 done\n100000 done\n110000 done\n120000 done\n130000 done\n140000 done\n150000 done\n160000 done\n170000 done\n180000 done\n190000 done\n200000 done\n"
    }
   ],
   "source": [
    "from dataproc import concat_and_split\n",
    "labeled = concat_and_split.concat_data_respiratory('%s/all_codes_filtered_ICD9.csv' % MIMIC_4_DIR, sorted_file, '%s/notes_labeled_ICD9.csv' % MIMIC_4_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CONCATENATING\n0 done\n10000 done\n20000 done\n30000 done\n40000 done\n50000 done\n60000 done\n70000 done\n80000 done\n90000 done\n100000 done\n110000 done\n120000 done\n"
    }
   ],
   "source": [
    "labeled = concat_and_split.concat_data_respiratory('%s/all_codes_filtered_ICD10.csv' % MIMIC_4_DIR, sorted_file, '%s/notes_labeled_ICD10.csv' % MIMIC_4_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter the data to only include respiratory ICD-codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICD-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = re.compile(\"4[6-9][0-9]|5[0-1][0-9].*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Let's filter out ICD9_CODEs\n",
    "with open('%s/all_codes_filtered_ICD9.csv' % MIMIC_4_DIR, 'r') as lf:\n",
    "    with open('%s/all_codes_respiratory_ICD9.csv' % MIMIC_4_DIR, 'w') as of:\n",
    "        w = csv.writer(of)\n",
    "        w.writerow(['SUBJECT_ID', 'HADM_ID', 'ICD_CODE', 'ADMITTIME', 'DISCHTIME'])\n",
    "        r = csv.reader(lf)\n",
    "        #header\n",
    "        next(r)\n",
    "        for i,row in enumerate(r):\n",
    "            icd_code = row[2]\n",
    "            if pattern.match(icd_code):\n",
    "                w.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.read_csv('%s/all_codes_respiratory_ICD9.csv' % MIMIC_4_DIR, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "67057"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "len(df_res['HADM_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we still need to sort it by HADM_ID\n",
    "df_res = df_res.sort_values(['SUBJECT_ID', 'HADM_ID'])\n",
    "df_res.to_csv('%s/all_codes_respiratory_ICD9.csv' % MIMIC_4_DIR, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CONCATENATING\n0 done\n10000 done\n20000 done\n30000 done\n40000 done\n50000 done\n60000 done\n"
    }
   ],
   "source": [
    "labeled_res = concat_and_split.concat_data_respiratory('%s/all_codes_respiratory_ICD9.csv' % MIMIC_4_DIR, sorted_file, '%s/notes_labeled_respiratory_ICD9.csv' % MIMIC_4_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "67057"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "dfnl_res = pd.read_csv(labeled_res)\n",
    "len(dfnl_res['HADM_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "67057"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "len(dfnl_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "223"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "df = pd.read_csv('%s/all_codes_respiratory_ICD9.csv' % MIMIC_4_DIR, dtype={\"ICD_CODE\": str})\n",
    "len(df['ICD_CODE'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['496.0', '486.0', '511.89', '511.9', '482.9', '518.0', '493.9',\n       '493.2', '487.1', '493.22', '491.22', '492.8', '518.89', '518.84',\n       '491.21', '518.81', '477.9', '518.4', '473.9', '494.0', '462.0',\n       '517.8', '478.19', '518.83', '482.41', '507.0', '482.49', '464.0',\n       '511.81', '512.89', '512.1', '465.9', '511.0', '493.92', '518.82',\n       '508.0', '515.0', '519.19', '510.9', '514.0', '482.0', '518.51',\n       '518.5', '516.8', '482.42', '488.1', '517.2', '478.2', '484.7',\n       '480.1', '484.6', '480.9', '482.39', '466.0', '487.0', '518.7',\n       '481.0', '501.0', '493.0', '477.0', '490.0', '482.81', '488.02',\n       '472.0', '494.1', '478.31', '491.2', '478.33', '478.6', '483.0',\n       '518.53', '518.3', '495.9', '513.0', '508.1', '465.8', '519.8',\n       '492.0', '519.2', '512.81', '512.8', '482.83', '519.02', '473.3',\n       '482.4', '519.3', '493.1', '510.0', '518.52', '474.8', '473.0',\n       '512.84', '461.0', '480.2', '516.31', '478.75', '493.02', '488.82',\n       '464.1', '519.4', '485.0', '519.09', '464.3', '461.9', '482.1',\n       '516.3', '478.3', '471.0', '478.5', '482.2', '518.1', '464.11',\n       '478.74', '493.81', '511.1', '477.8', '478.79', '484.8', '500.0',\n       '519.11', '482.82', '478.21', '478.29', '478.32', '466.19',\n       '473.2', '491.9', '474.9', '478.22', '482.84', '493.91', '491.8',\n       '473.8', '512.82', '512.0', '470.0', '519.01', '461.1', '517.3',\n       '513.1', '461.8', '512.2', '518.6', '516.33', '461.3', '511.8',\n       '466.11', '475.0', '460.0', '516.36', '464.31', '507.8', '473.1',\n       '471.8', '478.25', '482.32', '478.24', '482.3', '488.81', '519.9',\n       '464.5', '483.8', '488.89', '474.11', '464.51', '493.21', '488.01',\n       '508.2', '487.8', '478.0', '493.82', '478.4', '506.0', '478.7',\n       '484.1', '463.0', '480.8', '512.83', '502.0', '478.8', '478.11',\n       '474.02', '488.09', '495.8', '472.1', '482.31', '478.26', '508.8',\n       '461.2', '480.0', '516.2', '478.71', '516.0', '471.9', '516.4',\n       '516.1', '476.0', '491.0', '484.3', '493.12', '477.2', '516.37',\n       '516.32', '516.5', '493.01', '474.0', '465.0', '495.7', '482.89',\n       '472.2', '491.1', '478.9', '495.2', '488.0', '464.21', '516.35',\n       '516.34', '488.11', '478.34', '507.1', '471.1', '474.1', '474.12'],\n      dtype=object)"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "df['ICD_CODE'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICD 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's filter out ICD10_CODEs\n",
    "pattern = re.compile(\"J.*\")\n",
    "with open('%s/all_codes_filtered_ICD10.csv' % MIMIC_4_DIR, 'r') as lf:\n",
    "    with open('%s/all_codes_respiratory_ICD10.csv' % MIMIC_4_DIR, 'w') as of:\n",
    "        w = csv.writer(of)\n",
    "        w.writerow(['SUBJECT_ID', 'HADM_ID', 'ICD_CODE', 'ADMITTIME', 'DISCHTIME'])\n",
    "        r = csv.reader(lf)\n",
    "        #header\n",
    "        next(r)\n",
    "        for i,row in enumerate(r):\n",
    "            icd_code = row[2]\n",
    "            if pattern.match(icd_code):\n",
    "                w.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res_10 = pd.read_csv('%s/all_codes_respiratory_ICD10.csv' % MIMIC_4_DIR, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "42958"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "len(df_res_10['HADM_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we still need to sort it by HADM_ID\n",
    "df_res_10 = df_res_10.sort_values(['SUBJECT_ID', 'HADM_ID'])\n",
    "df_res_10.to_csv('%s/all_codes_respiratory_ICD10.csv' % MIMIC_4_DIR, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CONCATENATING\n0 done\n10000 done\n20000 done\n30000 done\n40000 done\n"
    }
   ],
   "source": [
    "labeled_res = concat_and_split.concat_data_respiratory('%s/all_codes_respiratory_ICD10.csv' % MIMIC_4_DIR, sorted_file, '%s/notes_labeled_respiratory_ICD10.csv' % MIMIC_4_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "42958"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "dfnl_res = pd.read_csv(labeled_res)\n",
    "len(dfnl_res['HADM_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "284"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "df = pd.read_csv('%s/all_codes_respiratory_ICD10.csv' % MIMIC_4_DIR, dtype={\"ICD_CODE\": str})\n",
    "len(df['ICD_CODE'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['J441', 'J45909', 'J9602', 'J9601', 'J0190', 'J449', 'J45998',\n       'J9811', 'J439', 'J189', 'J9691', 'J90', 'J4520', 'J9819', 'J910',\n       'J8410', 'J690', 'J95811', 'J9600', 'J309', 'J95821', 'J9690',\n       'J9621', 'J811', 'J952', 'J95851', 'J111', 'J869', 'J154', 'J9622',\n       'J398', 'J159', 'J208', 'J4541', 'J040', 'J479', 'J942', 'J939',\n       'J069', 'J9383', 'J9382', 'J982', 'J9809', 'J9610', 'J60',\n       'J45901', 'J329', 'J342', 'J84116', 'J810', 'J15211', 'J40',\n       'J029', 'J95812', 'J918', 'J3489', 'J9859', 'J9611', 'J984',\n       'J302', 'J440', 'J9692', 'J0180', 'J8489', 'J705', 'J988', 'J99',\n       'J09X2', 'J9572', 'J156', 'J95830', 'J151', 'J181', 'J9801',\n       'J702', 'J920', 'J122', 'J158', 'J390', 'J384', 'J849', 'J61',\n       'J852', 'J0110', 'J155', 'J14', 'J383', 'J310', 'J704', 'J101',\n       'J948', 'J80', 'J13', 'J00', 'J471', 'J129', 'J392', 'J188',\n       'J628', 'J986', 'J432', 'J9589', 'J698', 'J4550', 'J339', 'J324',\n       'J9851', 'J853', 'J940', 'J320', 'J322', 'J15212', 'J1108',\n       'J9584', 'J850', 'J95831', 'J985', 'J45990', 'J4551', 'J205',\n       'J438', 'J4530', 'J3801', 'J84112', 'J1000', 'J0430', 'J028',\n       'J209', 'J42', 'J82', 'J9503', 'J387', 'J989', 'J09X1', 'J9612',\n       'J929', 'J1008', 'J4521', 'J679', 'J0510', 'J9311', 'J9501', 'J36',\n       'J020', 'J9620', 'J701', 'J340', 'J386', 'J3802', 'J4540',\n       'J84111', 'J121', 'J150', 'J470', 'J323', 'J930', 'J95822',\n       'J9502', 'J9588', 'J1100', 'J3089', 'J851', 'J95860', 'J0410',\n       'J168', 'J9509', 'J860', 'J0390', 'J700', 'J341', 'J9571', 'J204',\n       'J0140', 'J3800', 'J301', 'J668', 'J1189', 'J338', 'J0100', 'J381',\n       'J4531', 'J391', 'J385', 'J955', 'J328', 'J9561', 'J680', 'J703',\n       'J358', 'J219', 'J941', 'J954', 'J180', 'J430', 'J1001', 'J1089',\n       'J09X9', 'J1529', 'J709', 'J042', 'J8417', 'J22', 'J17', 'J351',\n       'J691', 'J634', 'J343', 'J949', 'J9312', 'J9381', 'J8481', 'J8482',\n       'J410', 'J300', 'J0411', 'J1082', 'J1081', 'J218', 'J708', 'J0130',\n       'J102', 'J84114', 'J95861', 'J321', 'J689', 'J09X3', 'J951',\n       'J157', 'J45991', 'J1520', 'J84848', 'J3501', 'J3081', 'J3481',\n       'J1289', 'J210', 'J0120', 'J8403', 'J349', 'J4552', 'J45902',\n       'J312', 'J431', 'J662', 'J153', 'J370', 'J123', 'J84113', 'J4522',\n       'J0391', 'J84117', 'J330', 'J636', 'J201', 'J0301', 'J632', 'J359',\n       'J0380', 'J182', 'J1181', 'J0191', 'J684', 'J0511', 'J060',\n       'J0141', 'J84115', 'J842', 'J672', 'J9504', 'J688', 'J64', 'J120',\n       'J112', 'J411', 'J352', 'J681', 'J95863', 'J9562', 'J399',\n       'J95859', 'J678', 'J211', 'J8401', 'J0431'], dtype=object)"
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "df['ICD_CODE'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train/dev/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLITTING\n",
      "0 read\n",
      "10000 read\n",
      "20000 read\n",
      "30000 read\n",
      "40000 read\n",
      "50000 read\n"
     ]
    }
   ],
   "source": [
    "fname = '%s/notes_labeled.csv' % MIMIC_3_DIR\n",
    "base_name = \"%s/disch\" % MIMIC_3_DIR #for output\n",
    "tr, dv, te = concat_and_split.split_data(fname, base_name=base_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build vocabulary from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading in data...\n",
      "removing rare terms\n",
      "51917 terms qualify out of 140795 total\n",
      "writing output\n"
     ]
    }
   ],
   "source": [
    "vocab_min = 3\n",
    "vname = '%s/vocab.csv' % MIMIC_3_DIR\n",
    "build_vocab.build_vocab(vocab_min, tr, vname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Sort each data split by length for batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for splt in ['train', 'dev', 'test']:\n",
    "    filename = '%s/disch_%s_split.csv' % (MIMIC_3_DIR, splt)\n",
    "    df = pd.read_csv(filename)\n",
    "    df['length'] = df.apply(lambda row: len(str(row['TEXT']).split()), axis=1)\n",
    "    df = df.sort_values(['length'])\n",
    "    df.to_csv('%s/%s_full.csv' % (MIMIC_3_DIR, splt), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-train word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train word embeddings on all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building word2vec vocab on /nethome/jmullenbach3/replication/cnn-medical-text/mimicdata/mimic3//disch_full.csv...\n",
      "training...\n",
      "writing embeddings to /nethome/jmullenbach3/replication/cnn-medical-text/mimicdata/mimic3//processed_full.w2v\n"
     ]
    }
   ],
   "source": [
    "w2v_file = word_embeddings.word_embeddings('full', '%s/disch_full.csv' % MIMIC_3_DIR, 100, 0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write pre-trained word embeddings with new vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51917/51917 [02:58<00:00, 290.28it/s]\n"
     ]
    }
   ],
   "source": [
    "extract_wvs.gensim_to_embeddings('%s/processed_full.w2v' % MIMIC_3_DIR, '%s/vocab.csv' % MIMIC_3_DIR, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process code descriptions using the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22267/22267 [00:00<00:00, 62940.71it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab_index_descriptions.vocab_index_descriptions('%s/vocab.csv' % MIMIC_3_DIR,\n",
    "                                                  '%s/description_vectors.vocab' % MIMIC_3_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter each split to the top 50 diagnosis/procedure codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#first calculate the top k\n",
    "counts = Counter()\n",
    "dfnl = pd.read_csv('%s/notes_labeled.csv' % MIMIC_3_DIR)\n",
    "for row in dfnl.itertuples():\n",
    "    for label in str(row[4]).split(';'):\n",
    "        counts[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "codes_50 = sorted(counts.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "codes_50 = [code[0] for code in codes_50[:Y]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['401.9',\n",
       " '38.93',\n",
       " '428.0',\n",
       " '427.31',\n",
       " '414.01',\n",
       " '96.04',\n",
       " '96.6',\n",
       " '584.9',\n",
       " '250.00',\n",
       " '96.71',\n",
       " '272.4',\n",
       " '518.81',\n",
       " '99.04',\n",
       " '39.61',\n",
       " '599.0',\n",
       " '530.81',\n",
       " '96.72',\n",
       " '272.0',\n",
       " '285.9',\n",
       " '88.56',\n",
       " '244.9',\n",
       " '486',\n",
       " '38.91',\n",
       " '285.1',\n",
       " '36.15',\n",
       " '276.2',\n",
       " '496',\n",
       " '99.15',\n",
       " '995.92',\n",
       " 'V58.61',\n",
       " '507.0',\n",
       " '038.9',\n",
       " '88.72',\n",
       " '585.9',\n",
       " '403.90',\n",
       " '311',\n",
       " '305.1',\n",
       " '37.22',\n",
       " '412',\n",
       " '33.24',\n",
       " '39.95',\n",
       " '287.5',\n",
       " '410.71',\n",
       " '276.1',\n",
       " 'V45.81',\n",
       " '424.0',\n",
       " '45.13',\n",
       " 'V15.82',\n",
       " '511.9',\n",
       " '37.23']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('%s/TOP_%s_CODES.csv' % (MIMIC_3_DIR, str(Y)), 'w') as of:\n",
    "    w = csv.writer(of)\n",
    "    for code in codes_50:\n",
    "        w.writerow([code])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "dev\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "for splt in ['train', 'dev', 'test']:\n",
    "    print(splt)\n",
    "    hadm_ids = set()\n",
    "    with open('%s/%s_50_hadm_ids.csv' % (MIMIC_3_DIR, splt), 'r') as f:\n",
    "        for line in f:\n",
    "            hadm_ids.add(line.rstrip())\n",
    "    with open('%s/notes_labeled.csv' % MIMIC_3_DIR, 'r') as f:\n",
    "        with open('%s/%s_%s.csv' % (MIMIC_3_DIR, splt, str(Y)), 'w') as of:\n",
    "            r = csv.reader(f)\n",
    "            w = csv.writer(of)\n",
    "            #header\n",
    "            w.writerow(next(r))\n",
    "            i = 0\n",
    "            for row in r:\n",
    "                hadm_id = row[1]\n",
    "                if hadm_id not in hadm_ids:\n",
    "                    continue\n",
    "                codes = set(str(row[3]).split(';'))\n",
    "                filtered_codes = codes.intersection(set(codes_50))\n",
    "                if len(filtered_codes) > 0:\n",
    "                    w.writerow(row[:3] + [';'.join(filtered_codes)])\n",
    "                    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for splt in ['train', 'dev', 'test']:\n",
    "    filename = '%s/%s_%s.csv' % (MIMIC_3_DIR, splt, str(Y))\n",
    "    df = pd.read_csv(filename)\n",
    "    df['length'] = df.apply(lambda row: len(str(row['TEXT']).split()), axis=1)\n",
    "    df = df.sort_values(['length'])\n",
    "    df.to_csv('%s/%s_%s.csv' % (MIMIC_3_DIR, splt, str(Y)), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python39064biteaea6a66f983498d85afffa3b8a1ca59"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}